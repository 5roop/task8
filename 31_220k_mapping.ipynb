{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tries to train on the finalised dataset (196GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"ParlaSpeech-HR.v1.0.jsonl\", orient=\"records\", lines=True)\n",
    "#df[\"sentence\"] = df.norm_words.apply(\" \".join)\n",
    "df = df.rename(columns={\"path\":\"hashname\"})\n",
    "\n",
    "def process(text:str):\n",
    "    from parse import compile\n",
    "    from string import punctuation\n",
    "    p = compile(\"{hit:d}.\")\n",
    "    in_list = text.split()\n",
    "    out_list = list()\n",
    "    for seg in in_list:\n",
    "        parse_result = p.parse(seg)\n",
    "        if parse_result:\n",
    "            # We got a number with a dot afterward:\n",
    "            out_list.append(seg.lower())\n",
    "        else:\n",
    "            out_list.append(seg.translate(str.maketrans('', '', punctuation)).lower())\n",
    "    return \" \".join(out_list)\n",
    "df[\"sentence\"] = df.words.apply(\" \".join).apply(process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df.speaker_info.apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[df.split==\"dev\"].copy()\n",
    "is_train = df.split==\"train\" \n",
    "has_speaker_name =~df.Speaker_name.isna()\n",
    "speaker_name_is_not_dash = df.Speaker_name != \"-\"\n",
    "train_df = df[is_train & has_speaker_name & speaker_name_is_not_dash].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(new_indices)=304, len(speakers)=304\n",
      "len(new_indices)=608, len(speakers)=304\n",
      "len(new_indices)=912, len(speakers)=304\n",
      "len(new_indices)=1215, len(speakers)=303\n"
     ]
    }
   ],
   "source": [
    "new_indices = []\n",
    "target_size = 220000\n",
    "while len(new_indices) < target_size:\n",
    "    speakers = train_df.Speaker_name.unique()\n",
    "    for speaker in speakers:\n",
    "        ind = train_df[train_df.Speaker_name == speaker].index[0]\n",
    "        new_indices.append(ind)\n",
    "    train_df = train_df.drop(index=ind)\n",
    "    print(f\"{len(new_indices)=}, {len(speakers)=}\")\n",
    "\n",
    "train_df = df[is_train & has_speaker_name & speaker_name_is_not_dash].copy()\n",
    "train_df = train_df.loc[new_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220148, 22)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"hashname\", \"sentence\"]\n",
    "train_df = train_df.loc[:, columns_to_keep]\n",
    "test_df = test_df.loc[:, columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Use old or new vocab?\n",
    "os.system(\"cp vocab_300_with_numbers.json vocab.json\")\n",
    "\n",
    "\n",
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "from transformers import Wav2Vec2Processor\n",
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\n",
    "    \"./\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\" \")\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(\n",
    "    feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "\n",
    "processor = Wav2Vec2Processor(\n",
    "    feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "\n",
    "import torch\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "train_df[\"audio\"] = train_df.hashname.apply(lambda s: \"data_16000_mono/seg.\"+s)\n",
    "test_df[\"audio\"] = test_df.hashname.apply(lambda s: \"data_16000_mono/seg.\"+s)\n",
    "\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric, Audio\n",
    "\n",
    "train_dataset = datasets.Dataset.from_pandas(train_df)\n",
    "test_dataset = datasets.Dataset.from_pandas(test_df)\n",
    "\n",
    "train_dataset = train_dataset.cast_column(\"audio\", Audio())\n",
    "test_dataset = test_dataset.cast_column(\"audio\", Audio())\n",
    "\n",
    "del train_df\n",
    "del test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc511c68e4d47aabc2003f0becdf9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220148 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rupnik/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:99: RuntimeWarning: Mean of empty slice.\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/rupnik/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/rupnik/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:99: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/home/rupnik/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/rupnik/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6478fa58dee94f4aaa395f2890dd9674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation Complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2683"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Wav2Vec2ForCTC\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from dataclasses import dataclass, field\n",
    "import torch\n",
    "\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"sentence\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "train_mapped = train_dataset.map(\n",
    "    prepare_dataset, remove_columns=train_dataset.column_names, \n",
    "    #num_proc=8, \n",
    "    cache_file_name=\".cache_train\", )\n",
    "test_mapped = test_dataset.map(\n",
    "    prepare_dataset, remove_columns=test_dataset.column_names, \n",
    "    #num_proc=8, \n",
    "    cache_file_name=\".cache_test\", )\n",
    "print(\"Data Preparation Complete!\")\n",
    "\n",
    "del train_dataset\n",
    "del test_dataset\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mapped.save_to_disk(\"train220k_mapped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mapped.save_to_disk(\"test_mapped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f6f5766036ee03d059e365a942add07f79c17033585e9357ee8157d52fe6bb9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
